{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "425462cd-55ee-4b9c-9063-54d231bec7f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install --user --quiet google-cloud-aiplatform==1.25.0\n",
    "\n",
    "# Install pandas\n",
    "! pip install --user --quiet pandas\n",
    "\n",
    "# Install HuggingFace Datasets\n",
    "! pip install --user --quiet datasets\n",
    "\n",
    "# Install Python client for Google Search API\n",
    "! pip install --user --quiet google-api-python-client\n",
    "\n",
    "# PDF loader\n",
    "! pip install --user --quiet pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ef55029-ce33-4ea8-8447-dcebab85529d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Below libraries are required to build a SQL engine for BigQuery\n",
    "!pip install --user SQLAlchemy==1.4.48 --quiet\n",
    "!pip install --user sqlalchemy-bigquery --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8cec1a3-2398-456e-aa38-61a67af970c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: version\u001b[0m\u001b[33m\n",
      "\u001b[0mName: langchain\n",
      "Version: 0.0.229\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://www.github.com/hwchase17/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: aiohttp, async-timeout, dataclasses-json, langchainplus-sdk, numexpr, numpy, openapi-schema-pydantic, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langchain version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19259a3f-8864-4439-978f-b933323a001f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLAlchemy version: 1.4.48\n",
      "BigQuery version: 3.25.0\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "import google.cloud.bigquery\n",
    "\n",
    "print(f\"SQLAlchemy version: {sqlalchemy.__version__}\")\n",
    "print(f\"BigQuery version: {google.cloud.bigquery.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e6b1de-f9fc-4ffd-a16a-fbf8bb27c2fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "PROJECT_ID = \"sql-querygenerator\"  # Update this with your project id\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd6352a7-5551-4f13-80af-a82887677beb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain version: 0.0.229\n",
      "Vertex AI SDK version: 1.59.0\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(f\"LangChain version: {langchain.__version__}\")\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "import vertexai\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3682f5a1-587e-4528-8bb4-8d8ca4ed9bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Any, Mapping, List, Dict, Optional, Tuple, Union\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from pydantic import BaseModel, Extra, root_validator\n",
    "\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.chat_models.base import BaseChatModel\n",
    "from langchain.llms.utils import enforce_stop_tokens\n",
    "from langchain.schema import Generation, LLMResult\n",
    "from langchain.schema import AIMessage, BaseMessage, ChatGeneration, ChatResult, HumanMessage, SystemMessage\n",
    "\n",
    "from vertexai.preview.language_models import TextGenerationResponse, ChatSession\n",
    "\n",
    "def rate_limit(max_per_minute):\n",
    "    period = 60 / max_per_minute\n",
    "    print('Waiting')\n",
    "    while True:\n",
    "        before = time.time()\n",
    "        yield\n",
    "        after = time.time()\n",
    "        elapsed = after - before\n",
    "        sleep_time = max(0, period - elapsed)\n",
    "        if sleep_time > 0:\n",
    "            print('.', end='')\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "class _VertexCommon(BaseModel):\n",
    "    client: Any = None\n",
    "    model_name: str = \"text-bison@001\"\n",
    "    temperature: float = 0.2\n",
    "    top_p: int = 0.8\n",
    "    top_k: int = 40\n",
    "    max_output_tokens: int = 200\n",
    "\n",
    "    @property\n",
    "    def _default_params(self) -> Mapping[str, Any]:\n",
    "        return {\n",
    "            \"temperature\": self.temperature,\n",
    "            \"top_p\": self.top_p,\n",
    "            \"top_k\": self.top_k,\n",
    "            \"max_output_tokens\": self.max_output_tokens\n",
    "        }\n",
    "\n",
    "    def _predict(self, prompt: str, stop: Optional[List[str]]) -> str:\n",
    "        res = self.client.predict(prompt, **self._default_params)\n",
    "        return self._enforce_stop_words(res.text, stop)\n",
    "\n",
    "    def _enforce_stop_words(self, text: str, stop: Optional[List[str]]) -> str:\n",
    "        if stop:\n",
    "            return enforce_stop_tokens(text, stop)\n",
    "        return text\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"vertex_ai\"\n",
    "\n",
    "class VertexLLM(_VertexCommon, LLM):\n",
    "    model_name: str = \"text-bison@001\"\n",
    "\n",
    "    @root_validator(allow_reuse=True)\n",
    "    def validate_environment(cls, values: Dict) -> Dict:\n",
    "        try:\n",
    "            from vertexai.preview.language_models import TextGenerationModel\n",
    "        except ImportError:\n",
    "            raise ValueError(\"Could not import Vertex AI LLM python package.\")\n",
    "        try:\n",
    "            values[\"client\"] = TextGenerationModel.from_pretrained(values[\"model_name\"])\n",
    "        except AttributeError:\n",
    "            raise ValueError(\"Could not set Vertex Text Model client.\")\n",
    "        return values\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        return self._predict(prompt, stop)\n",
    "\n",
    "@dataclass\n",
    "class _MessagePair:\n",
    "    question: HumanMessage\n",
    "    answer: AIMessage\n",
    "\n",
    "@dataclass\n",
    "class _ChatHistory:\n",
    "    history: List[_MessagePair] = field(default_factory=list)\n",
    "    system_message: Optional[SystemMessage] = None\n",
    "\n",
    "def _parse_chat_history(history: List[BaseMessage]) -> _ChatHistory:\n",
    "    if not history:\n",
    "        return _ChatHistory()\n",
    "    first_message = history[0]\n",
    "    system_message = first_message if isinstance(first_message, SystemMessage) else None\n",
    "    chat_history = _ChatHistory(system_message=system_message)\n",
    "    messages_left = history[1:] if system_message else history\n",
    "    for question, answer in zip(messages_left[::2], messages_left[1::2]):\n",
    "        if not isinstance(question, HumanMessage) or not isinstance(answer, AIMessage):\n",
    "            raise ValueError(\"A human message should follow a bot one.\")\n",
    "        chat_history.history.append(_MessagePair(question=question, answer=answer))\n",
    "    return chat_history\n",
    "\n",
    "class _VertexChatCommon(_VertexCommon):\n",
    "    model_name: str = \"chat-bison@001\"\n",
    "\n",
    "    @root_validator(allow_reuse=True)\n",
    "    def validate_environment(cls, values: Dict) -> Dict:\n",
    "        try:\n",
    "            from vertexai.preview.language_models import ChatModel\n",
    "        except ImportError:\n",
    "            raise ValueError(\"Could not import Vertex AI LLM python package.\")\n",
    "        try:\n",
    "            values[\"client\"] = ChatModel.from_pretrained(values[\"model_name\"])\n",
    "        except AttributeError:\n",
    "            raise ValueError(\"Could not set Vertex Text Model client.\")\n",
    "        return values\n",
    "\n",
    "    def _response_to_chat_results(self, response: TextGenerationResponse, stop: Optional[List[str]]) -> ChatResult:\n",
    "        text = self._enforce_stop_words(response.text, stop)\n",
    "        return ChatResult(generations=[ChatGeneration(message=AIMessage(content=text))])\n",
    "\n",
    "class VertexChat(_VertexChatCommon, BaseChatModel):\n",
    "    model_name: str = \"chat-bison@001\"\n",
    "    chat: Any = None\n",
    "\n",
    "    def send_message(self, message: Union[HumanMessage, str], stop: Optional[List[str]] = None) -> ChatResult:\n",
    "        text = message.content if isinstance(message, BaseMessage) else message\n",
    "        response = self.chat.send_message(text)\n",
    "        text = self._enforce_stop_words(response.text, stop)\n",
    "        return ChatResult(generations=[ChatGeneration(message=AIMessage(content=text))])\n",
    "\n",
    "    def _generate(self, messages: List[BaseMessage], stop: Optional[List[str]]) -> ChatResult:\n",
    "        if not messages:\n",
    "            raise ValueError(\"You should provide at least one message to start the chat!\")\n",
    "        question = messages[-1]\n",
    "        if not isinstance(question, HumanMessage):\n",
    "            raise ValueError(f\"Last message in the list should be from human, got {question.type}.\")\n",
    "        self.start_chat(messages[:-1])\n",
    "        return self.send_message(question)\n",
    "\n",
    "    def start_chat(self, messages: List[BaseMessage]) -> None:\n",
    "        history = _parse_chat_history(messages)\n",
    "        context = history.system_message.content if history.system_message else None\n",
    "        self.chat = self.client.start_chat(context=context, **self._default_params)\n",
    "        for pair in history.history:\n",
    "            self.chat._history.append((pair.question.content, pair.answer.content))\n",
    "\n",
    "    def clear_chat(self) -> None:\n",
    "        self.chat = None\n",
    "\n",
    "    @property\n",
    "    def history(self) -> List[BaseMessage]:\n",
    "        history: List[BaseMessage] = []\n",
    "        if self.chat:\n",
    "            for question, answer in self.chat._history:\n",
    "                history.append(HumanMessage(content=question))\n",
    "                history.append(AIMessage(content=answer))\n",
    "        return history\n",
    "\n",
    "    async def _agenerate(self, messages: List[BaseMessage], stop: Optional[List[str]]) -> ChatResult:\n",
    "        raise NotImplementedError(\"Vertex AI doesn't support async requests at the moment.\")\n",
    "\n",
    "class VertexMultiTurnChat(_VertexChatCommon, BaseChatModel):\n",
    "    model_name: str = \"chat-bison@001\"\n",
    "    chat: Optional[ChatSession] = None\n",
    "\n",
    "    def clear_chat(self) -> None:\n",
    "        self.chat = None\n",
    "\n",
    "    def start_chat(self, message: Optional[SystemMessage] = None) -> None:\n",
    "        if self.chat:\n",
    "            raise ValueError(\"Chat has already been started. Please, clear it first.\")\n",
    "        if message and not isinstance(message, SystemMessage):\n",
    "            raise ValueError(\"Context should be a system message\")\n",
    "        context = message.content if message else None\n",
    "        self.chat = self.client.start_chat(context=context, **self._default_params)\n",
    "\n",
    "    @property\n",
    "    def history(self) -> List[Tuple[str]]:\n",
    "        if self.chat:\n",
    "            return self.chat._history\n",
    "        return []\n",
    "\n",
    "    def _generate(self, messages: List[BaseMessage], stop: Optional[List[str]]) -> ChatResult:\n",
    "        if len(messages) != 1:\n",
    "            raise ValueError(\"You should send exactly one message to the chat each turn.\")\n",
    "        if not self.chat:\n",
    "            raise ValueError(\"You should start_chat first!\")\n",
    "        response = self.chat.send_message(messages[0].content)\n",
    "        return self._response_to_chat_results(response, stop=stop)\n",
    "\n",
    "    async def _agenerate(self, messages: List[BaseMessage], stop: Optional[List[str]]) -> ChatResult:\n",
    "        raise NotImplementedError(\"Vertex AI doesn't support async requests at the moment.\")\n",
    "\n",
    "class VertexEmbeddings(Embeddings, BaseModel):\n",
    "    model_name: str = \"textembedding-gecko@001\"\n",
    "    model: Any\n",
    "    requests_per_minute: int = 15\n",
    "\n",
    "    @root_validator(allow_reuse=True)\n",
    "    def validate_environment(cls, values: Dict) -> Dict:\n",
    "        try:\n",
    "            from vertexai.preview.language_models import TextEmbeddingModel\n",
    "        except ImportError:\n",
    "            raise ValueError(\"Could not import Vertex AI LLM python package.\")\n",
    "        try:\n",
    "            values[\"model\"] = TextEmbeddingModel\n",
    "        except AttributeError:\n",
    "            raise ValueError(\"Could not set Vertex Text Model client.\")\n",
    "        return values\n",
    "\n",
    "    class Config:\n",
    "        extra = Extra.forbid\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        self.model = self.model.from_pretrained(self.model_name)\n",
    "        limiter = rate_limit(self.requests_per_minute)\n",
    "        results = []\n",
    "        docs = list(texts)\n",
    "        while docs:\n",
    "            head, docs = docs[:2], docs[2:]\n",
    "            chunk = self.model.get_embeddings(head)\n",
    "            results.extend(chunk)\n",
    "            next(limiter)\n",
    "        return [r.values for r in results]\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        single_result = self.embed_documents([text])\n",
    "        return single_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a63f02e-128a-499e-a05f-3f3d7d478214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REQUESTS_PER_MINUTE = 100\n",
    "\n",
    "llm = VertexLLM(\n",
    "    model_name='text-bison@001',\n",
    "    max_output_tokens=1024,\n",
    "    temperature=0.1,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chat = VertexChat()\n",
    "\n",
    "mchat = VertexMultiTurnChat(max_output_tokens=1024)\n",
    "\n",
    "embedding = VertexEmbeddings(requests_per_minute=REQUESTS_PER_MINUTE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "325598ef-545e-47cd-b14d-07ea4d479406",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets in bigquery-public-data:\n",
      "['america_health_rankings', 'austin_311', 'austin_bikeshare', 'austin_crime', 'austin_incidents', 'austin_waste', 'baseball', 'bbc_news', 'bigqueryml_ncaa', 'bitcoin_blockchain', 'blackhole_database', 'blockchain_analytics_ethereum_mainnet_us', 'bls', 'bls_qcew', 'breathe', 'broadstreet_adi', 'catalonian_mobile_coverage', 'catalonian_mobile_coverage_eu', 'census_bureau_acs', 'census_bureau_construction', 'census_bureau_international', 'census_bureau_usa', 'census_opportunity_atlas', 'census_utility', 'cfpb_complaints', 'chicago_crime', 'chicago_taxi_trips', 'clemson_dice', 'cloud_storage_geo_index', 'cms_codes', 'cms_medicare', 'cms_synthetic_patient_data_omop', 'country_codes', 'covid19_aha', 'covid19_covidtracking', 'covid19_ecdc', 'covid19_ecdc_eu', 'covid19_genome_sequence', 'covid19_geotab_mobility_impact', 'covid19_geotab_mobility_impact_eu', 'covid19_google_mobility', 'covid19_google_mobility_eu', 'covid19_govt_response', 'covid19_italy', 'covid19_italy_eu', 'covid19_jhu_csse', 'covid19_jhu_csse_eu', 'covid19_nyt', 'covid19_open_data', 'covid19_open_data_eu', 'covid19_public_forecasts', 'covid19_public_forecasts_asia_ne1', 'covid19_rxrx19', 'covid19_symptom_search', 'covid19_tracking', 'covid19_usafacts', 'covid19_vaccination_access', 'covid19_vaccination_search_insights', 'covid19_weathersource_com', 'crypto_aptos_mainnet_us', 'crypto_aptos_testnet_us', 'crypto_band', 'crypto_bitcoin', 'crypto_bitcoin_cash', 'crypto_dash', 'crypto_dogecoin', 'crypto_ethereum', 'crypto_ethereum_classic', 'crypto_iotex', 'crypto_kusama', 'crypto_litecoin', 'crypto_multiversx_mainnet_eu', 'crypto_near_mainnet_us', 'crypto_polkadot', 'crypto_polygon', 'crypto_solana_mainnet_us', 'crypto_sui_mainnet_us', 'crypto_tezos', 'crypto_theta', 'crypto_zcash', 'crypto_zilliqa', 'cymbal_investments', 'dataflix_covid', 'dataflix_traffic_safety', 'deepmind_alphafold', 'deps_dev_v1', 'dimensions_ai_covid19', 'ebi_chembl', 'ebi_surechembl', 'eclipse_megamovie', 'epa_historical_air_quality', 'ethereum_blockchain', 'etsi_technical_standards', 'faa', 'fcc_political_ads', 'fda_drug', 'fda_food', 'fdic_banks', 'fec', 'fhir_synthea', 'ga4_obfuscated_sample_ecommerce', 'gbif', 'gdelt_hathitrustbooks', 'gdelt_internetarchivebooks', 'genomics_cannabis', 'genomics_rice', 'geo_census_blockgroups', 'geo_census_tracts', 'geo_international_ports', 'geo_openstreetmap', 'geo_us_boundaries', 'geo_us_census_places', 'geo_us_roads', 'geo_whos_on_first', 'ghcn_d', 'ghcn_m', 'github_repos', 'gnomAD', 'gnomAD_asiane1', 'gnomAD_eu', 'goog_blockchain_arbitrum_one_us', 'goog_blockchain_avalanche_contract_chain_us', 'goog_blockchain_cronos_mainnet_us', 'goog_blockchain_ethereum_goerli_us', 'goog_blockchain_ethereum_mainnet_us', 'goog_blockchain_fantom_opera_us', 'goog_blockchain_optimism_mainnet_us', 'goog_blockchain_polygon_mainnet_us', 'goog_blockchain_tron_mainnet_us', 'google_ads', 'google_ads_geo_mapping_asia_east1', 'google_ads_geo_mapping_asia_east2', 'google_ads_geo_mapping_asia_northeast1', 'google_ads_geo_mapping_asia_northeast2', 'google_ads_geo_mapping_asia_northeast3', 'google_ads_geo_mapping_asia_south1', 'google_ads_geo_mapping_asia_south2', 'google_ads_geo_mapping_asia_southeast1', 'google_ads_geo_mapping_asia_southeast2', 'google_ads_geo_mapping_australia_southeast1', 'google_ads_geo_mapping_australia_southeast2', 'google_ads_geo_mapping_eu', 'google_ads_geo_mapping_europe_central2', 'google_ads_geo_mapping_europe_north1', 'google_ads_geo_mapping_europe_southwest1', 'google_ads_geo_mapping_europe_west1', 'google_ads_geo_mapping_europe_west12', 'google_ads_geo_mapping_europe_west2', 'google_ads_geo_mapping_europe_west3', 'google_ads_geo_mapping_europe_west4', 'google_ads_geo_mapping_europe_west6', 'google_ads_geo_mapping_europe_west8', 'google_ads_geo_mapping_europe_west9', 'google_ads_geo_mapping_me_central1', 'google_ads_geo_mapping_me_central2', 'google_ads_geo_mapping_me_west1', 'google_ads_geo_mapping_northamerica_northeast1', 'google_ads_geo_mapping_northamerica_northeast2', 'google_ads_geo_mapping_southamerica_east1', 'google_ads_geo_mapping_southamerica_west1', 'google_ads_geo_mapping_us', 'google_ads_geo_mapping_us_central1', 'google_ads_geo_mapping_us_central2', 'google_ads_geo_mapping_us_east1', 'google_ads_geo_mapping_us_east4', 'google_ads_geo_mapping_us_east5', 'google_ads_geo_mapping_us_south1', 'google_ads_geo_mapping_us_west1', 'google_ads_geo_mapping_us_west2', 'google_ads_geo_mapping_us_west3', 'google_ads_geo_mapping_us_west4', 'google_ads_transparency_center', 'google_analytics_sample', 'google_books_ngrams_2020', 'google_cfe', 'google_cloud_release_notes', 'google_dei', 'google_patents_research', 'google_political_ads', 'google_trends', 'gretel_synthetic_text_to_sql', 'grid_ac', 'hacker_news', 'hud_zipcode_crosswalk', 'human_genome_variants', 'human_variant_annotation', 'idc_current', 'idc_current_clinical', 'idc_v1', 'idc_v10', 'idc_v11', 'idc_v11_clinical', 'idc_v12', 'idc_v12_clinical', 'idc_v13', 'idc_v13_clinical', 'idc_v14', 'idc_v14_clinical', 'idc_v15', 'idc_v15_clinical', 'idc_v16', 'idc_v16_clinical', 'idc_v17', 'idc_v17_clinical', 'idc_v18', 'idc_v18_clinical', 'idc_v2', 'idc_v3', 'idc_v4', 'idc_v5', 'idc_v6', 'idc_v7', 'idc_v8', 'idc_v9', 'imdb', 'immune_epitope_db', 'iowa_liquor_sales', 'iowa_liquor_sales_forecasting', 'irs_990', 'labeled_patents', 'libraries_io', 'listenbrainz', 'london_bicycles', 'london_crime', 'london_fire_brigade', 'marec', 'medicare', 'ml_datasets', 'ml_datasets_uscentral1', 'modis_terra_net_primary_production', 'moon_phases', 'multilingual_spoken_words_corpus', 'nasa_wildfire', 'national_water_model', 'ncaa_basketball', 'nces_ipeds', 'new_york', 'new_york_311', 'new_york_citibike', 'new_york_mv_collisions', 'new_york_subway', 'new_york_taxi_trips', 'new_york_trees', 'nhtsa_traffic_fatalities', 'nih_gudid', 'nih_sequence_read', 'nlm_rxnorm', 'noaa_global_forecast_system', 'noaa_goes16', 'noaa_goes17', 'noaa_gsod', 'noaa_historic_severe_storms', 'noaa_hurricanes', 'noaa_icoads', 'noaa_lightning', 'noaa_nwm', 'noaa_passive_acoustic_index', 'noaa_passive_bioacoustic', 'noaa_pifsc_metadata', 'noaa_preliminary_severe_storms', 'noaa_significant_earthquakes', 'noaa_tsunami', 'nppes', 'nrel_nsrdb', 'open_buildings', 'open_images', 'open_targets_genetics', 'open_targets_platform', 'openaq', 'overture_maps', 'patents', 'patents_cpc', 'patents_dsep', 'patents_view', 'persistent_udfs', 'properati_properties_ar', 'properati_properties_br', 'properati_properties_cl', 'properati_properties_co', 'properati_properties_mx', 'properati_properties_pe', 'properati_properties_uy', 'pypi', 'samples', 'san_francisco', 'san_francisco_311', 'san_francisco_bikeshare', 'san_francisco_film_locations', 'san_francisco_neighborhoods', 'san_francisco_sffd_service_calls', 'san_francisco_sfpd_incidents', 'san_francisco_transit_muni', 'san_francisco_trees', 'sdoh_bea_cainc30', 'sdoh_cdc_wonder_natality', 'sdoh_cms_dual_eligible_enrollment', 'sdoh_hrsa_shortage_areas', 'sdoh_hud_housing', 'sdoh_hud_pit_homelessness', 'sdoh_snap_enrollment', 'sec_quarterly_financials', 'stackoverflow', 'sunroof_solar', 'the_general_index', 'the_met', 'thelook_ecommerce', 'ucb_fung_patent_data', 'umiami_lincs', 'un_sdg', 'us_res_real_est_data', 'usa_contagious_disease', 'usa_names', 'usda_nass_agriculture', 'usfs_fia', 'usitc_investigations', 'uspto_oce_assignment', 'uspto_oce_cancer', 'uspto_oce_claims', 'uspto_oce_litigation', 'uspto_oce_office_actions', 'uspto_oce_pair', 'uspto_ptab', 'utility_eu', 'utility_us', 'wikipedia', 'wise_all_sky_data_release', 'world_bank_global_population', 'world_bank_health_population', 'world_bank_intl_debt', 'world_bank_intl_education', 'world_bank_wdi', 'worldbank_wdi', 'worldpop']\n",
      "Selected Dataset: america_health_rankings\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery import Client\n",
    "\n",
    "client = Client(project=PROJECT_ID)\n",
    "\n",
    "# List datasets in the bigquery-public-data project\n",
    "datasets = list(client.list_datasets(project=\"bigquery-public-data\"))\n",
    "\n",
    "dataset_names = [dataset.dataset_id for dataset in datasets]\n",
    "print(\"Datasets in bigquery-public-data:\")\n",
    "print(dataset_names)\n",
    "\n",
    "# Select a dataset (simulate user selection)\n",
    "selected_dataset = dataset_names[0]  # For example, you can change this to any dataset from the list\n",
    "print(f\"Selected Dataset: {selected_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4adb8c5c-b582-4cfa-b86d-56e92a6cc1a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in selected dataset:\n",
      "['ahr', 'america_health_rankings']\n",
      "Selected Table: ahr\n"
     ]
    }
   ],
   "source": [
    "# List tables in the selected dataset\n",
    "tables = list(client.list_tables(dataset=f\"bigquery-public-data.{selected_dataset}\"))\n",
    "table_names = [table.table_id for table in tables]\n",
    "print(\"Tables in selected dataset:\")\n",
    "print(table_names)\n",
    "\n",
    "# Select a table (simulate user selection)\n",
    "selected_table = table_names[0]  # For example, you can change this to any table from the list\n",
    "print(f\"Selected Table: {selected_table}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8456fb31-696d-4e9b-aba6-b8f4378cb3d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field: edition, Type: INTEGER\n",
      "Field: report_type, Type: STRING\n",
      "Field: measure_name, Type: STRING\n",
      "Field: state_name, Type: STRING\n",
      "Field: subpopulation, Type: STRING\n",
      "Field: value, Type: FLOAT\n",
      "Field: lower_ci, Type: FLOAT\n",
      "Field: upper_ci, Type: FLOAT\n",
      "Field: source, Type: STRING\n",
      "Field: source_date, Type: STRING\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# Define the source table\n",
    "source_table_id = f\"bigquery-public-data.america_health_rankings.ahr\"\n",
    "\n",
    "# Get the schema of the source table\n",
    "table = client.get_table(source_table_id)\n",
    "schema = table.schema\n",
    "\n",
    "# Print the schema\n",
    "for field in schema:\n",
    "    print(f\"Field: {field.name}, Type: {field.field_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6e4f8f7-0431-40f4-89a7-4827c654a661",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['edition', 'report_type', 'measure_name', 'state_name', 'subpopulation', 'value', 'lower_ci', 'upper_ci', 'source', 'source_date']\n"
     ]
    }
   ],
   "source": [
    "# Extract and print the column names\n",
    "column_names = [field.name for field in schema]\n",
    "print(\"Column names:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa22db29-67b2-4def-b18a-1c68e1284ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset america_health_rankings already exists.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery import Client\n",
    "\n",
    "client = Client(project=PROJECT_ID)\n",
    "dataset_id = \"america_health_rankings\"\n",
    "\n",
    "# Check if dataset exists\n",
    "datasets = list(client.list_datasets())\n",
    "dataset_exists = any(dataset.dataset_id == dataset_id for dataset in datasets)\n",
    "\n",
    "if not dataset_exists:\n",
    "    query = f\"\"\"\n",
    "    CREATE SCHEMA `{PROJECT_ID}.{dataset_id}`\n",
    "    OPTIONS(\n",
    "      location=\"us\"\n",
    "    )\n",
    "    \"\"\"\n",
    "    query_job = client.query(query)\n",
    "    print(query_job.result())\n",
    "else:\n",
    "    print(f\"Dataset {dataset_id} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a70a26ff-58be-438a-ae34-b8052c520856",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<google.cloud.bigquery.table._EmptyRowIterator object at 0x7f7b9be5aaa0>\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "create or replace table `{PROJECT_ID}.{dataset_id}.ahr`\n",
    "as\n",
    "select \n",
    "edition,\n",
    "report_type, \n",
    "measure_name, \n",
    "state_name,\n",
    "subpopulation, \n",
    "value, \n",
    "lower_ci, \n",
    "upper_ci, \n",
    "source, \n",
    "source_date\n",
    "from `bigquery-public-data.america_health_rankings.ahr`\n",
    "\"\"\".format(\n",
    "    PROJECT_ID=PROJECT_ID, dataset_id=dataset_id,\n",
    ")\n",
    "query_job = client.query(query)\n",
    "print(query_job.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e248834e-873d-4c34-a7d5-cd6501b973ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_id = PROJECT_ID  # @param {type:\"string\"}\n",
    "location = LOCATION  # @param {type:\"string\"}\n",
    "dataset_id = 'america_health_rankings' # @param {type:\"string\"}\n",
    "table_name = 'ahr' # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "699c740f-e620-4c62-a877-5d2ba7c4891b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import *\n",
    "from sqlalchemy.engine import create_engine\n",
    "from sqlalchemy.schema import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "974fd95c-b40e-44f8-bb5a-2f037754dc90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_uri = f\"bigquery://{project_id}/{dataset_id}\"\n",
    "engine = create_engine(f\"bigquery://{project_id}/{dataset_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0218eb0-243b-451c-bbbd-1b408fe7954c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_131639/4098976475.py:2: RemovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  engine.execute(query).first()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2021, '2021 Health Disparities', 'Asthma', 'Vermont', 'Black/African American', None, None, None, 'CDC, Behavioral Risk Factor Surveillance System', '2017-2019')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=f\"\"\"SELECT * FROM `{project_id}.{dataset_id}.{table_name}`\"\"\"\n",
    "engine.execute(query).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20a64230-0a1b-4b66-8057-4da5d881f2bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "You are a BigQuery SQL expert. Given an input question, first create a syntactically correct BigQuery query to run, then look at the results of the query and return the answer to the input question.\n",
      "    Unless the user specifies in the question a specific number of examples to obtain, query for at most 10000 results using the LIMIT clause as per BigQuery SQL. You can order the results to return the most informative data in the database.\n",
      "    Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
      "    Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "    Use the following format:\n",
      "    Question: \"Question here\"\n",
      "    SQLQuery: \"SQL Query to run\"\n",
      "    SQLResult: \"Result of the SQLQuery\"\n",
      "    Answer: \"Final answer here\"\n",
      "    Only use the following tables:\n",
      "    ahr\n",
      "\n",
      "    If someone asks for a specific month, use ActivityDate between current month's start date and current month's end date\n",
      "\n",
      "    Question: Count total number of reports\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT COUNT(*) FROM `ahr`\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(18155,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m18155\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Result: 18155\n",
      "Intermediate Steps: {'input': 'You are a BigQuery SQL expert. Given an input question, first create a syntactically correct BigQuery query to run, then look at the results of the query and return the answer to the input question.\\n    Unless the user specifies in the question a specific number of examples to obtain, query for at most 10000 results using the LIMIT clause as per BigQuery SQL. You can order the results to return the most informative data in the database.\\n    Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\\n    Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\n    Use the following format:\\n    Question: \"Question here\"\\n    SQLQuery: \"SQL Query to run\"\\n    SQLResult: \"Result of the SQLQuery\"\\n    Answer: \"Final answer here\"\\n    Only use the following tables:\\n    ahr\\n\\n    If someone asks for a specific month, use ActivityDate between current month\\'s start date and current month\\'s end date\\n\\n    Question: Count total number of reports\\nSQLQuery:SELECT COUNT(*) FROM `ahr`\\nSQLResult: [(18155,)]\\nAnswer:', 'top_k': '5', 'dialect': 'bigquery', 'table_info': '\\nCREATE TABLE `ahr` (\\n\\t`edition` INT64, \\n\\t`report_type` STRING, \\n\\t`measure_name` STRING, \\n\\t`state_name` STRING, \\n\\t`subpopulation` STRING, \\n\\t`value` FLOAT64, \\n\\t`lower_ci` FLOAT64, \\n\\t`upper_ci` FLOAT64, \\n\\t`source` STRING, \\n\\t`source_date` STRING\\n)\\n\\n/*\\n3 rows from ahr table:\\nedition\\treport_type\\tmeasure_name\\tstate_name\\tsubpopulation\\tvalue\\tlower_ci\\tupper_ci\\tsource\\tsource_date\\n2021\\t2021 Health Disparities\\tAsthma\\tVermont\\tBlack/African American\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n2021\\t2021 Health Disparities\\tAsthma\\tNew Hampshire\\tAsian/Pacific Islander\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n2021\\t2021 Health Disparities\\tAsthma\\tLouisiana\\tAsian/Pacific Islander\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n*/', 'stop': ['\\nSQLResult:']}\n"
     ]
    }
   ],
   "source": [
    "from langchain import SQLDatabase, SQLDatabaseChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "def bq_qna(question):\n",
    "    # Create SQLDatabase instance from BQ engine\n",
    "    db = SQLDatabase(engine=engine, metadata=MetaData(bind=engine), include_tables=[table_name])\n",
    "    \n",
    "    # Create SQL DB Chain with the initialized LLM and above SQLDB instance\n",
    "    db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True, return_intermediate_steps=True)\n",
    "\n",
    "    # Define prompt for BigQuery SQL\n",
    "    _googlesql_prompt = \"\"\"You are a BigQuery SQL expert. Given an input question, first create a syntactically correct BigQuery query to run, then look at the results of the query and return the answer to the input question.\n",
    "    Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per BigQuery SQL. You can order the results to return the most informative data in the database.\n",
    "    Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
    "    Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "    Use the following format:\n",
    "    Question: \"Question here\"\n",
    "    SQLQuery: \"SQL Query to run\"\n",
    "    SQLResult: \"Result of the SQLQuery\"\n",
    "    Answer: \"Final answer here\"\n",
    "    Only use the following tables:\n",
    "    {table_info}\n",
    "\n",
    "    If someone asks for a specific month, use ActivityDate between current month's start date and current month's end date\n",
    "\n",
    "    Question: {input}\"\"\"\n",
    "\n",
    "    BigQuerySQL_PROMPT = PromptTemplate(\n",
    "        input_variables=[\"input\", \"table_info\", \"top_k\"],\n",
    "        template=_googlesql_prompt,\n",
    "    )\n",
    "\n",
    "    # Passing question to the prompt template\n",
    "    final_prompt = BigQuerySQL_PROMPT.format(input=question, table_info=table_name, top_k=10000)\n",
    "\n",
    "    # Pass final prompt to SQL Chain\n",
    "    output = db_chain(final_prompt)\n",
    "\n",
    "    return output['result'], output['intermediate_steps'][0]\n",
    "\n",
    "# Testing the function\n",
    "result, steps = bq_qna('Count total number of reports')\n",
    "print(\"Result:\", result)\n",
    "print(\"Intermediate Steps:\", steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a1efe9a-e167-42e3-a204-cef300eee30d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "955ca29b-70a3-42d0-9e16-49d5aa2b0f90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing stapp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stapp.py\n",
    "\n",
    "import streamlit as st\n",
    "st.title(\"Text to SQL on BigQuery Dataset with LangChain\")\n",
    "\n",
    "st.write(\"Ask a question about the dataset:\")\n",
    "\n",
    "question = st.text_input(\"Question\")\n",
    "\n",
    "if st.button(\"Get Answer\"):\n",
    "    if question:\n",
    "        sql_query, results = bq_qna(question)\n",
    "        st.write(\"Generated SQL Query:\")\n",
    "        st.code(sql_query)\n",
    "        st.write(\"Query Results:\")\n",
    "        st.write(results)\n",
    "    else:\n",
    "        st.error(\"Please enter a question.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29da86ca-f0f0-4fc5-813b-f40f6df89a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.197.237.27\n",
      "2024-07-22 02:16:01.150 INFO    numexpr.utils: NumExpr defaulting to 4 threads.\n",
      "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0Kyour url is: https://dry-tigers-film.loca.lt\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.128.0.2:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://104.197.237.27:8501\u001b[0m\n",
      "\u001b[0m\n",
      "2024-07-22 02:16:45.905 Uncaught app exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/streamlit/scriptrunner/script_runner.py\", line 554, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"stapp.py\", line 11, in <module>\n",
      "    sql_query, results = bq_qna(question)\n",
      "NameError: name 'bq_qna' is not defined\n"
     ]
    }
   ],
   "source": [
    "!wget -q -O - ipv4.icanhazip.com\n",
    "! streamlit run stapp.py & npx localtunnel --port 8501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6cf81a7e-f533-4622-9772-4380775f1f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "You are a BigQuery SQL expert. Given an input question, first create a syntactically correct BigQuery query to run, then look at the results of the query and return the answer to the input question.\n",
      "    Unless the user specifies in the question a specific number of examples to obtain, query for at most 10000 results using the LIMIT clause as per BigQuery SQL. You can order the results to return the most informative data in the database.\n",
      "    Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
      "    Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "    Use the following format:\n",
      "    Question: \"Question here\"\n",
      "    SQLQuery: \"SQL Query to run\"\n",
      "    SQLResult: \"Result of the SQLQuery\"\n",
      "    Answer: \"Final answer here\"\n",
      "    Only use the following tables:\n",
      "    ahr\n",
      "\n",
      "    If someone asks for a specific month, use ActivityDate between current month's start date and current month's end date\n",
      "\n",
      "    Question: which state has the highest value\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT state_name, value FROM ahr ORDER BY value DESC LIMIT 1\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('District of Columbia', 102684.0)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mDistrict of Columbia\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('District of Columbia',\n",
       " {'input': 'You are a BigQuery SQL expert. Given an input question, first create a syntactically correct BigQuery query to run, then look at the results of the query and return the answer to the input question.\\n    Unless the user specifies in the question a specific number of examples to obtain, query for at most 10000 results using the LIMIT clause as per BigQuery SQL. You can order the results to return the most informative data in the database.\\n    Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\\n    Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\n    Use the following format:\\n    Question: \"Question here\"\\n    SQLQuery: \"SQL Query to run\"\\n    SQLResult: \"Result of the SQLQuery\"\\n    Answer: \"Final answer here\"\\n    Only use the following tables:\\n    ahr\\n\\n    If someone asks for a specific month, use ActivityDate between current month\\'s start date and current month\\'s end date\\n\\n    Question: which state has the highest value\\nSQLQuery:SELECT state_name, value FROM ahr ORDER BY value DESC LIMIT 1\\nSQLResult: [(\\'District of Columbia\\', 102684.0)]\\nAnswer:',\n",
       "  'top_k': '5',\n",
       "  'dialect': 'bigquery',\n",
       "  'table_info': '\\nCREATE TABLE `ahr` (\\n\\t`edition` INT64, \\n\\t`report_type` STRING, \\n\\t`measure_name` STRING, \\n\\t`state_name` STRING, \\n\\t`subpopulation` STRING, \\n\\t`value` FLOAT64, \\n\\t`lower_ci` FLOAT64, \\n\\t`upper_ci` FLOAT64, \\n\\t`source` STRING, \\n\\t`source_date` STRING\\n)\\n\\n/*\\n3 rows from ahr table:\\nedition\\treport_type\\tmeasure_name\\tstate_name\\tsubpopulation\\tvalue\\tlower_ci\\tupper_ci\\tsource\\tsource_date\\n2021\\t2021 Health Disparities\\tAsthma\\tIdaho\\tAsian/Pacific Islander\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n2021\\t2021 Health Disparities\\tAsthma\\tMaine\\tBlack/African American\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n2021\\t2021 Health Disparities\\tAsthma\\tGeorgia\\tOther Race\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n*/',\n",
       "  'stop': ['\\nSQLResult:']})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_qna('which state has the highest value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36657f00-298e-47fe-9e05-93e474d953c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "You are a BigQuery SQL expert. Given an input question, first create a syntactically correct BigQuery query to run, then look at the results of the query and return the answer to the input question.\n",
      "    Unless the user specifies in the question a specific number of examples to obtain, query for at most 10000 results using the LIMIT clause as per BigQuery SQL. You can order the results to return the most informative data in the database.\n",
      "    Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
      "    Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "    Use the following format:\n",
      "    Question: \"Question here\"\n",
      "    SQLQuery: \"SQL Query to run\"\n",
      "    SQLResult: \"Result of the SQLQuery\"\n",
      "    Answer: \"Final answer here\"\n",
      "    Only use the following tables:\n",
      "    ahr\n",
      "\n",
      "    If someone asks for a specific month, use ActivityDate between current month's start date and current month's end date\n",
      "\n",
      "    Question: which state has the lowest value\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT state_name FROM ahr ORDER BY value LIMIT 1\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('Idaho',)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mIdaho\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Idaho',\n",
       " {'input': 'You are a BigQuery SQL expert. Given an input question, first create a syntactically correct BigQuery query to run, then look at the results of the query and return the answer to the input question.\\n    Unless the user specifies in the question a specific number of examples to obtain, query for at most 10000 results using the LIMIT clause as per BigQuery SQL. You can order the results to return the most informative data in the database.\\n    Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\\n    Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\n    Use the following format:\\n    Question: \"Question here\"\\n    SQLQuery: \"SQL Query to run\"\\n    SQLResult: \"Result of the SQLQuery\"\\n    Answer: \"Final answer here\"\\n    Only use the following tables:\\n    ahr\\n\\n    If someone asks for a specific month, use ActivityDate between current month\\'s start date and current month\\'s end date\\n\\n    Question: which state has the lowest value\\nSQLQuery:SELECT state_name FROM ahr ORDER BY value LIMIT 1\\nSQLResult: [(\\'Idaho\\',)]\\nAnswer:',\n",
       "  'top_k': '5',\n",
       "  'dialect': 'bigquery',\n",
       "  'table_info': '\\nCREATE TABLE `ahr` (\\n\\t`edition` INT64, \\n\\t`report_type` STRING, \\n\\t`measure_name` STRING, \\n\\t`state_name` STRING, \\n\\t`subpopulation` STRING, \\n\\t`value` FLOAT64, \\n\\t`lower_ci` FLOAT64, \\n\\t`upper_ci` FLOAT64, \\n\\t`source` STRING, \\n\\t`source_date` STRING\\n)\\n\\n/*\\n3 rows from ahr table:\\nedition\\treport_type\\tmeasure_name\\tstate_name\\tsubpopulation\\tvalue\\tlower_ci\\tupper_ci\\tsource\\tsource_date\\n2021\\t2021 Health Disparities\\tAsthma\\tIdaho\\tAsian/Pacific Islander\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n2021\\t2021 Health Disparities\\tAsthma\\tMaine\\tBlack/African American\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n2021\\t2021 Health Disparities\\tAsthma\\tGeorgia\\tOther Race\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n*/',\n",
       "  'stop': ['\\nSQLResult:']})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_qna('which state has the lowest value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a64a2994-9f47-4544-915d-f9663f18c203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "You are a BigQuery SQL expert. Given an input question, first create a syntactically correct BigQuery query to run, then look at the results of the query and return the answer to the input question.\n",
      "    Unless the user specifies in the question a specific number of examples to obtain, query for at most 10000 results using the LIMIT clause as per BigQuery SQL. You can order the results to return the most informative data in the database.\n",
      "    Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
      "    Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "    Use the following format:\n",
      "    Question: \"Question here\"\n",
      "    SQLQuery: \"SQL Query to run\"\n",
      "    SQLResult: \"Result of the SQLQuery\"\n",
      "    Answer: \"Final answer here\"\n",
      "    Only use the following tables:\n",
      "    ahr\n",
      "\n",
      "    If someone asks for a specific month, use ActivityDate between current month's start date and current month's end date\n",
      "\n",
      "    Question: How many subpopulation categories were present in the table\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT count(distinct(subpopulation)) FROM ahr\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(15,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m15\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('15',\n",
       " {'input': 'You are a BigQuery SQL expert. Given an input question, first create a syntactically correct BigQuery query to run, then look at the results of the query and return the answer to the input question.\\n    Unless the user specifies in the question a specific number of examples to obtain, query for at most 10000 results using the LIMIT clause as per BigQuery SQL. You can order the results to return the most informative data in the database.\\n    Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\\n    Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\n    Use the following format:\\n    Question: \"Question here\"\\n    SQLQuery: \"SQL Query to run\"\\n    SQLResult: \"Result of the SQLQuery\"\\n    Answer: \"Final answer here\"\\n    Only use the following tables:\\n    ahr\\n\\n    If someone asks for a specific month, use ActivityDate between current month\\'s start date and current month\\'s end date\\n\\n    Question: How many subpopulation categories were present in the table\\nSQLQuery:SELECT count(distinct(subpopulation)) FROM ahr\\nSQLResult: [(15,)]\\nAnswer:',\n",
       "  'top_k': '5',\n",
       "  'dialect': 'bigquery',\n",
       "  'table_info': '\\nCREATE TABLE `ahr` (\\n\\t`edition` INT64, \\n\\t`report_type` STRING, \\n\\t`measure_name` STRING, \\n\\t`state_name` STRING, \\n\\t`subpopulation` STRING, \\n\\t`value` FLOAT64, \\n\\t`lower_ci` FLOAT64, \\n\\t`upper_ci` FLOAT64, \\n\\t`source` STRING, \\n\\t`source_date` STRING\\n)\\n\\n/*\\n3 rows from ahr table:\\nedition\\treport_type\\tmeasure_name\\tstate_name\\tsubpopulation\\tvalue\\tlower_ci\\tupper_ci\\tsource\\tsource_date\\n2021\\t2021 Health Disparities\\tAsthma\\tIdaho\\tAsian/Pacific Islander\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n2021\\t2021 Health Disparities\\tAsthma\\tMaine\\tBlack/African American\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n2021\\t2021 Health Disparities\\tAsthma\\tGeorgia\\tOther Race\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n*/',\n",
       "  'stop': ['\\nSQLResult:']})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_qna('How many subpopulation categories were present in the table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2458a15-300a-4d22-aa7f-98e018560311",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "You are a BigQuery SQL expert. Given an input question, first create a syntactically correct BigQuery query to run, then look at the results of the query and return the answer to the input question.\n",
      "    Unless the user specifies in the question a specific number of examples to obtain, query for at most 10000 results using the LIMIT clause as per BigQuery SQL. You can order the results to return the most informative data in the database.\n",
      "    Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
      "    Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "    Use the following format:\n",
      "    Question: \"Question here\"\n",
      "    SQLQuery: \"SQL Query to run\"\n",
      "    SQLResult: \"Result of the SQLQuery\"\n",
      "    Answer: \"Final answer here\"\n",
      "    Only use the following tables:\n",
      "    ahr\n",
      "\n",
      "    If someone asks for a specific month, use ActivityDate between current month's start date and current month's end date\n",
      "\n",
      "    Question: Name subpopulation categories were present in the table\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT DISTINCT subpopulation FROM `ahr`\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('Asian/Pacific Islander',), ('Black/African American',), ('Other Race',), ('American Indian/Alaska Native',), ('Hispanic',), ('Multiracial',), ('Non-Metropolitan Area',), ('White',), ('College Grad',), ('Female',), ('Metropolitan Area',), ('Male',), ('Some College',), (None,), ('Less Than High School',), ('High School Grad',)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mAsian/Pacific Islander, Black/African American, Other Race, American Indian/Alaska Native, Hispanic, Multiracial, Non-Metropolitan Area, White, College Grad, Female, Metropolitan Area, Male, Some College, None, Less Than High School, High School Grad\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Asian/Pacific Islander, Black/African American, Other Race, American Indian/Alaska Native, Hispanic, Multiracial, Non-Metropolitan Area, White, College Grad, Female, Metropolitan Area, Male, Some College, None, Less Than High School, High School Grad',\n",
       " {'input': 'You are a BigQuery SQL expert. Given an input question, first create a syntactically correct BigQuery query to run, then look at the results of the query and return the answer to the input question.\\n    Unless the user specifies in the question a specific number of examples to obtain, query for at most 10000 results using the LIMIT clause as per BigQuery SQL. You can order the results to return the most informative data in the database.\\n    Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\\n    Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\n    Use the following format:\\n    Question: \"Question here\"\\n    SQLQuery: \"SQL Query to run\"\\n    SQLResult: \"Result of the SQLQuery\"\\n    Answer: \"Final answer here\"\\n    Only use the following tables:\\n    ahr\\n\\n    If someone asks for a specific month, use ActivityDate between current month\\'s start date and current month\\'s end date\\n\\n    Question: Name subpopulation categories were present in the table\\nSQLQuery:SELECT DISTINCT subpopulation FROM `ahr`\\nSQLResult: [(\\'Asian/Pacific Islander\\',), (\\'Black/African American\\',), (\\'Other Race\\',), (\\'American Indian/Alaska Native\\',), (\\'Hispanic\\',), (\\'Multiracial\\',), (\\'Non-Metropolitan Area\\',), (\\'White\\',), (\\'College Grad\\',), (\\'Female\\',), (\\'Metropolitan Area\\',), (\\'Male\\',), (\\'Some College\\',), (None,), (\\'Less Than High School\\',), (\\'High School Grad\\',)]\\nAnswer:',\n",
       "  'top_k': '5',\n",
       "  'dialect': 'bigquery',\n",
       "  'table_info': '\\nCREATE TABLE `ahr` (\\n\\t`edition` INT64, \\n\\t`report_type` STRING, \\n\\t`measure_name` STRING, \\n\\t`state_name` STRING, \\n\\t`subpopulation` STRING, \\n\\t`value` FLOAT64, \\n\\t`lower_ci` FLOAT64, \\n\\t`upper_ci` FLOAT64, \\n\\t`source` STRING, \\n\\t`source_date` STRING\\n)\\n\\n/*\\n3 rows from ahr table:\\nedition\\treport_type\\tmeasure_name\\tstate_name\\tsubpopulation\\tvalue\\tlower_ci\\tupper_ci\\tsource\\tsource_date\\n2021\\t2021 Health Disparities\\tAsthma\\tIdaho\\tAsian/Pacific Islander\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n2021\\t2021 Health Disparities\\tAsthma\\tMaine\\tBlack/African American\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n2021\\t2021 Health Disparities\\tAsthma\\tGeorgia\\tOther Race\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n*/',\n",
       "  'stop': ['\\nSQLResult:']})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_qna('Name subpopulation categories were present in the table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a41fcfe4-9578-4c27-be69-2221bc75d755",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "You are a BigQuery SQL expert. Given an input question, first create a syntactically correct BigQuery query to run, then look at the results of the query and return the answer to the input question.\n",
      "    Unless the user specifies in the question a specific number of examples to obtain, query for at most 10000 results using the LIMIT clause as per BigQuery SQL. You can order the results to return the most informative data in the database.\n",
      "    Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
      "    Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "    Use the following format:\n",
      "    Question: \"Question here\"\n",
      "    SQLQuery: \"SQL Query to run\"\n",
      "    SQLResult: \"Result of the SQLQuery\"\n",
      "    Answer: \"Final answer here\"\n",
      "    Only use the following tables:\n",
      "    ahr\n",
      "\n",
      "    If someone asks for a specific month, use ActivityDate between current month's start date and current month's end date\n",
      "\n",
      "    Question: what is the value present in male and female for Washington\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT value FROM `ahr` WHERE state_name = \"Washington\" AND subpopulation = \"Male\"\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(5.0,), (6.0,), (7.0,), (7.0,), (7.0,), (8.0,), (8.0,), (9.0,), (9.0,), (10.0,), (10.0,), (10.0,), (14.0,), (14.0,), (17.0,), (18.0,), (20.0,), (40.0,), (69.0,), (85.0,), (51.0,), (7400.0,), (48871.0,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m5.0\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('5.0',\n",
       " {'input': 'You are a BigQuery SQL expert. Given an input question, first create a syntactically correct BigQuery query to run, then look at the results of the query and return the answer to the input question.\\n    Unless the user specifies in the question a specific number of examples to obtain, query for at most 10000 results using the LIMIT clause as per BigQuery SQL. You can order the results to return the most informative data in the database.\\n    Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\\n    Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\n    Use the following format:\\n    Question: \"Question here\"\\n    SQLQuery: \"SQL Query to run\"\\n    SQLResult: \"Result of the SQLQuery\"\\n    Answer: \"Final answer here\"\\n    Only use the following tables:\\n    ahr\\n\\n    If someone asks for a specific month, use ActivityDate between current month\\'s start date and current month\\'s end date\\n\\n    Question: what is the value present in male and female for Washington\\nSQLQuery:SELECT value FROM `ahr` WHERE state_name = \"Washington\" AND subpopulation = \"Male\"\\nSQLResult: [(5.0,), (6.0,), (7.0,), (7.0,), (7.0,), (8.0,), (8.0,), (9.0,), (9.0,), (10.0,), (10.0,), (10.0,), (14.0,), (14.0,), (17.0,), (18.0,), (20.0,), (40.0,), (69.0,), (85.0,), (51.0,), (7400.0,), (48871.0,)]\\nAnswer:',\n",
       "  'top_k': '5',\n",
       "  'dialect': 'bigquery',\n",
       "  'table_info': '\\nCREATE TABLE `ahr` (\\n\\t`edition` INT64, \\n\\t`report_type` STRING, \\n\\t`measure_name` STRING, \\n\\t`state_name` STRING, \\n\\t`subpopulation` STRING, \\n\\t`value` FLOAT64, \\n\\t`lower_ci` FLOAT64, \\n\\t`upper_ci` FLOAT64, \\n\\t`source` STRING, \\n\\t`source_date` STRING\\n)\\n\\n/*\\n3 rows from ahr table:\\nedition\\treport_type\\tmeasure_name\\tstate_name\\tsubpopulation\\tvalue\\tlower_ci\\tupper_ci\\tsource\\tsource_date\\n2021\\t2021 Health Disparities\\tAsthma\\tIdaho\\tAsian/Pacific Islander\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n2021\\t2021 Health Disparities\\tAsthma\\tMaine\\tBlack/African American\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n2021\\t2021 Health Disparities\\tAsthma\\tGeorgia\\tOther Race\\tNone\\tNone\\tNone\\tCDC, Behavioral Risk Factor Surveillance System\\t2017-2019\\n*/',\n",
       "  'stop': ['\\nSQLResult:']})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_qna('what is the value present in male and female for Washington')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cdfb23-921a-4584-a03b-92cdbdf7bdac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
